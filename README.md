# Neural-Network
# Lab01

```python
X = heart_disease.data.features
y = heart_disease.data.targets
```

## Og√≥lny przeglƒÖd danych

Additional Information

This database contains 76 attributes, but all published experiments refer to using a subset of 14 of them.  In particular, the Cleveland database is the only one that has been used by ML researchers to date.  The "goal" field refers to the presence of heart disease in the patient.  It is integer valued from 0 (no presence) to 4. Experiments with the Cleveland database have concentrated on simply attempting to distinguish presence (values 1,2,3,4) from absence (value 0).

warto≈õci liczbowe atrybutu num:
    -0 brak oznak choroby
    -1,2,3,4 wystƒôpujƒÖce oznaki choroby


```python
# variable information
variable_info = heart_disease.variables
variable_info
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>name</th>
      <th>role</th>
      <th>type</th>
      <th>demographic</th>
      <th>description</th>
      <th>units</th>
      <th>missing_values</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>age</td>
      <td>Feature</td>
      <td>Integer</td>
      <td>Age</td>
      <td>None</td>
      <td>years</td>
      <td>no</td>
    </tr>
    <tr>
      <th>1</th>
      <td>sex</td>
      <td>Feature</td>
      <td>Categorical</td>
      <td>Sex</td>
      <td>None</td>
      <td>None</td>
      <td>no</td>
    </tr>
    <tr>
      <th>2</th>
      <td>cp</td>
      <td>Feature</td>
      <td>Categorical</td>
      <td>None</td>
      <td>None</td>
      <td>None</td>
      <td>no</td>
    </tr>
    <tr>
      <th>3</th>
      <td>trestbps</td>
      <td>Feature</td>
      <td>Integer</td>
      <td>None</td>
      <td>resting blood pressure (on admission to the ho...</td>
      <td>mm Hg</td>
      <td>no</td>
    </tr>
    <tr>
      <th>4</th>
      <td>chol</td>
      <td>Feature</td>
      <td>Integer</td>
      <td>None</td>
      <td>serum cholestoral</td>
      <td>mg/dl</td>
      <td>no</td>
    </tr>
    <tr>
      <th>5</th>
      <td>fbs</td>
      <td>Feature</td>
      <td>Categorical</td>
      <td>None</td>
      <td>fasting blood sugar &gt; 120 mg/dl</td>
      <td>None</td>
      <td>no</td>
    </tr>
    <tr>
      <th>6</th>
      <td>restecg</td>
      <td>Feature</td>
      <td>Categorical</td>
      <td>None</td>
      <td>None</td>
      <td>None</td>
      <td>no</td>
    </tr>
    <tr>
      <th>7</th>
      <td>thalach</td>
      <td>Feature</td>
      <td>Integer</td>
      <td>None</td>
      <td>maximum heart rate achieved</td>
      <td>None</td>
      <td>no</td>
    </tr>
    <tr>
      <th>8</th>
      <td>exang</td>
      <td>Feature</td>
      <td>Categorical</td>
      <td>None</td>
      <td>exercise induced angina</td>
      <td>None</td>
      <td>no</td>
    </tr>
    <tr>
      <th>9</th>
      <td>oldpeak</td>
      <td>Feature</td>
      <td>Integer</td>
      <td>None</td>
      <td>ST depression induced by exercise relative to ...</td>
      <td>None</td>
      <td>no</td>
    </tr>
    <tr>
      <th>10</th>
      <td>slope</td>
      <td>Feature</td>
      <td>Categorical</td>
      <td>None</td>
      <td>None</td>
      <td>None</td>
      <td>no</td>
    </tr>
    <tr>
      <th>11</th>
      <td>ca</td>
      <td>Feature</td>
      <td>Integer</td>
      <td>None</td>
      <td>number of major vessels (0-3) colored by flour...</td>
      <td>None</td>
      <td>yes</td>
    </tr>
    <tr>
      <th>12</th>
      <td>thal</td>
      <td>Feature</td>
      <td>Categorical</td>
      <td>None</td>
      <td>None</td>
      <td>None</td>
      <td>yes</td>
    </tr>
    <tr>
      <th>13</th>
      <td>num</td>
      <td>Target</td>
      <td>Integer</td>
      <td>None</td>
      <td>diagnosis of heart disease</td>
      <td>None</td>
      <td>no</td>
    </tr>
  </tbody>
</table>
</div>




```python
X
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>age</th>
      <th>sex</th>
      <th>cp</th>
      <th>trestbps</th>
      <th>chol</th>
      <th>fbs</th>
      <th>restecg</th>
      <th>thalach</th>
      <th>exang</th>
      <th>oldpeak</th>
      <th>slope</th>
      <th>ca</th>
      <th>thal</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>63</td>
      <td>1</td>
      <td>1</td>
      <td>145</td>
      <td>233</td>
      <td>1</td>
      <td>2</td>
      <td>150</td>
      <td>0</td>
      <td>2.3</td>
      <td>3</td>
      <td>0.0</td>
      <td>6.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>67</td>
      <td>1</td>
      <td>4</td>
      <td>160</td>
      <td>286</td>
      <td>0</td>
      <td>2</td>
      <td>108</td>
      <td>1</td>
      <td>1.5</td>
      <td>2</td>
      <td>3.0</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>67</td>
      <td>1</td>
      <td>4</td>
      <td>120</td>
      <td>229</td>
      <td>0</td>
      <td>2</td>
      <td>129</td>
      <td>1</td>
      <td>2.6</td>
      <td>2</td>
      <td>2.0</td>
      <td>7.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>37</td>
      <td>1</td>
      <td>3</td>
      <td>130</td>
      <td>250</td>
      <td>0</td>
      <td>0</td>
      <td>187</td>
      <td>0</td>
      <td>3.5</td>
      <td>3</td>
      <td>0.0</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>41</td>
      <td>0</td>
      <td>2</td>
      <td>130</td>
      <td>204</td>
      <td>0</td>
      <td>2</td>
      <td>172</td>
      <td>0</td>
      <td>1.4</td>
      <td>1</td>
      <td>0.0</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>298</th>
      <td>45</td>
      <td>1</td>
      <td>1</td>
      <td>110</td>
      <td>264</td>
      <td>0</td>
      <td>0</td>
      <td>132</td>
      <td>0</td>
      <td>1.2</td>
      <td>2</td>
      <td>0.0</td>
      <td>7.0</td>
    </tr>
    <tr>
      <th>299</th>
      <td>68</td>
      <td>1</td>
      <td>4</td>
      <td>144</td>
      <td>193</td>
      <td>1</td>
      <td>0</td>
      <td>141</td>
      <td>0</td>
      <td>3.4</td>
      <td>2</td>
      <td>2.0</td>
      <td>7.0</td>
    </tr>
    <tr>
      <th>300</th>
      <td>57</td>
      <td>1</td>
      <td>4</td>
      <td>130</td>
      <td>131</td>
      <td>0</td>
      <td>0</td>
      <td>115</td>
      <td>1</td>
      <td>1.2</td>
      <td>2</td>
      <td>1.0</td>
      <td>7.0</td>
    </tr>
    <tr>
      <th>301</th>
      <td>57</td>
      <td>0</td>
      <td>2</td>
      <td>130</td>
      <td>236</td>
      <td>0</td>
      <td>2</td>
      <td>174</td>
      <td>0</td>
      <td>0.0</td>
      <td>2</td>
      <td>1.0</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>302</th>
      <td>38</td>
      <td>1</td>
      <td>3</td>
      <td>138</td>
      <td>175</td>
      <td>0</td>
      <td>0</td>
      <td>173</td>
      <td>0</td>
      <td>0.0</td>
      <td>1</td>
      <td>NaN</td>
      <td>3.0</td>
    </tr>
  </tbody>
</table>
<p>303 rows √ó 13 columns</p>
</div>




```python
y
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>num</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
    </tr>
    <tr>
      <th>298</th>
      <td>1</td>
    </tr>
    <tr>
      <th>299</th>
      <td>2</td>
    </tr>
    <tr>
      <th>300</th>
      <td>3</td>
    </tr>
    <tr>
      <th>301</th>
      <td>1</td>
    </tr>
    <tr>
      <th>302</th>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>303 rows √ó 1 columns</p>
</div>



## 1.Czy zbi√≥r jest zbalansowany pod wzglƒôdem liczby pr√≥bek na klasy?


```python
y_value_counts = y.value_counts()
y_value_counts
```




    num
    0      164
    1       55
    2       36
    3       35
    4       13
    Name: count, dtype: int64




```python
y_value_counts.plot(kind='barh')
```




    <Axes: ylabel='num'>




    
![png](../media/Lab01_files/Lab02_11_1.png)
    



```python
y_value_counts.plot(kind='pie', autopct='%1.1f%%')
```




    <Axes: ylabel='count'>




    
![png](../media/Lab01_files/Lab02_12_1.png)
    


Mo≈ºna zauwa≈ºyƒá, ≈ºe najwiƒôcej przypadk√≥w jest dla warto≈õci 0, kt√≥ra stanowi ponad po≈Çowƒô wszystkich warto≈õci, je≈õli chodzi o pozosta≈Çe, przypadek 1 posiada r√≥wnie≈º du≈ºy wk≈Çad, 2 i 3 majƒÖ prawie takƒÖ samƒÖ czƒôstotliwo≈õƒá na poziomie ok.12%, przypadek 4 jest najmniej liczny i stanowi nieca≈Çe 5%.

Odpowied≈∫:
Zbi√≥r danych nie jest najlepiej zbalansowany, poniewa≈º niekt√≥re klasy majƒÖ znacznie wiƒôcej pr√≥bek ni≈º inne.


```python
no_presence = y[y==0].count().sum()
presence = y[y!=0].count().sum()
presence,no_presence
```




    (139, 164)




```python
# Create a bar chart
plt.bar(['No Presence', 'Presence'], [no_presence, presence])
plt.xlabel('Class')
plt.ylabel('Count')
plt.title('Bar Chart: No Presence vs. Presence')
```




    Text(0.5, 1.0, 'Bar Chart: No Presence vs. Presence')




    
![png](../media/Lab01_files/Lab02_16_1.png)
    



```python
labels = ['No Presence', 'Presence']
sizes = [no_presence, presence]
plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)
plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.
plt.title('Pie Chart: No Presence vs. Presence')
```




    Text(0.5, 1.0, 'Pie Chart: No Presence vs. Presence')




    
![png](../media/Lab01_files/Lab02_17_1.png)
    


Je≈õli jednak p√≥j≈õƒá dalej i zobaczyƒá na warto≈õci atrybutu num w perspektywie - 'ma objawy' 'nie ma objawow', rozk≈Çad bƒôdzie bardziej zbalansowany.

## 2. Jakie sƒÖ ≈õrednie i odchylenia cech liczbowych?


```python
numeric_variables = variable_info[(variable_info['type']=='Integer') & (variable_info['name']!='num')]['name']
numeric_variables
```




    0          age
    3     trestbps
    4         chol
    7      thalach
    9      oldpeak
    11          ca
    Name: name, dtype: object




```python
X[numeric_variables].describe().loc[['mean','std']]
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>age</th>
      <th>trestbps</th>
      <th>chol</th>
      <th>thalach</th>
      <th>oldpeak</th>
      <th>ca</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>mean</th>
      <td>54.438944</td>
      <td>131.689769</td>
      <td>246.693069</td>
      <td>149.607261</td>
      <td>1.039604</td>
      <td>0.672241</td>
    </tr>
    <tr>
      <th>std</th>
      <td>9.038662</td>
      <td>17.599748</td>
      <td>51.776918</td>
      <td>22.875003</td>
      <td>1.161075</td>
      <td>0.937438</td>
    </tr>
  </tbody>
</table>
</div>



## 3. Dla cech liczbowych: czy ich rozk≈Çad jest w przybli≈ºeniu normalny?


```python
from scipy import stats
```


```python
numeric_df = X[numeric_variables]
numeric_df
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>age</th>
      <th>trestbps</th>
      <th>chol</th>
      <th>thalach</th>
      <th>oldpeak</th>
      <th>ca</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>63</td>
      <td>145</td>
      <td>233</td>
      <td>150</td>
      <td>2.3</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>67</td>
      <td>160</td>
      <td>286</td>
      <td>108</td>
      <td>1.5</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>67</td>
      <td>120</td>
      <td>229</td>
      <td>129</td>
      <td>2.6</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>37</td>
      <td>130</td>
      <td>250</td>
      <td>187</td>
      <td>3.5</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>41</td>
      <td>130</td>
      <td>204</td>
      <td>172</td>
      <td>1.4</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>298</th>
      <td>45</td>
      <td>110</td>
      <td>264</td>
      <td>132</td>
      <td>1.2</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>299</th>
      <td>68</td>
      <td>144</td>
      <td>193</td>
      <td>141</td>
      <td>3.4</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>300</th>
      <td>57</td>
      <td>130</td>
      <td>131</td>
      <td>115</td>
      <td>1.2</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>301</th>
      <td>57</td>
      <td>130</td>
      <td>236</td>
      <td>174</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>302</th>
      <td>38</td>
      <td>138</td>
      <td>175</td>
      <td>173</td>
      <td>0.0</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>303 rows √ó 6 columns</p>
</div>




```python
# Perform the Shapiro-Wilk test and create histograms for each attribute
for column in numeric_df.columns:
    # Shapiro-Wilk test
    p_value = stats.shapiro(numeric_df[column])[1]

    # Create a histogram
    plt.figure(figsize=(8, 4))
    plt.subplot(1, 2, 1)
    plt.hist(numeric_df[column], bins=15, color='blue', edgecolor='black')
    plt.xlabel(column)
    plt.ylabel('Frequency')
    plt.title('Histogram')

    # Check normality based on p-value
    plt.subplot(1, 2, 2)
    if p_value > 0.05:
        plt.text(0.1, 0.5, f'p-value: {p_value:.4f}\nProbably Normal', fontsize=12)
    else:
        plt.text(0.1, 0.5, f'p-value: {p_value:.4f}\nNot Normal', fontsize=12, color='red')
    plt.axis('off')
    plt.title('Shapiro-Wilk Test')

    plt.tight_layout()
    plt.show()
```


    
![png](../media/Lab01_files/Lab02_25_0.png)
    



    
![png](../media/Lab01_files/Lab02_25_1.png)
    



    
![png](../media/Lab01_files/Lab02_25_2.png)
    



    
![png](../media/Lab01_files/Lab02_25_3.png)
    



    
![png](../media/Lab01_files/Lab02_25_4.png)
    



    
![png](../media/Lab01_files/Lab02_25_5.png)
    



```python
import statsmodels.api as sm
```


```python
num_bins = 15

# Iterate through each column and create histograms and QQ plots
for column in numeric_df.columns:
    # Create a figure with subplots (histogram and QQ plot)
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))

    # Create a histogram
    ax1.hist(numeric_df[column], bins=num_bins, color='blue', edgecolor='black')
    ax1.set_xlabel(column)
    ax1.set_ylabel('Frequency')
    ax1.set_title('Histogram')

    # Create a QQ plot for the transformed data
    sm.qqplot(numeric_df[column], line='s', ax=ax2)
    ax2.set_title('QQ Plot')

    plt.tight_layout()
    plt.show()
```


    
![png](../media/Lab01_files/Lab02_27_0.png)
    



    
![png](../media/Lab01_files/Lab02_27_1.png)
    



    
![png](../media/Lab01_files/Lab02_27_2.png)
    



    
![png](../media/Lab01_files/Lab02_27_3.png)
    



    
![png](../media/Lab01_files/Lab02_27_4.png)
    



    
![png](../media/Lab01_files/Lab02_27_5.png)
    



BadajƒÖc te kwestiƒô postanowi≈Çem sprawdziƒá najpierw testem Shapiro-Wilka, czy warto≈õci sƒÖ rozdystrybuowane w spos√≥b normalny, jednak patrzƒÖc na histogramy danych i wyniki testu postanowi≈Çem sprawdziƒá czy dane sƒÖ w 'przybli≈ºeniu' rozdystrybuowane w spos√≥b normalny, wiƒôc postanowi≈Çem sprawdziƒá mniej restrykcyjnym testem. Wykres kwantylowy (qqplot). Mo≈ºna z tego wyciƒÖgnƒÖƒá, ≈ºe atrybuty:
- thalach
- chol
- age

majƒÖ rozk≈Çad podobny do normalnego.

## 4. Dla cech kategorycznych: czy rozk≈Çad jest w przybli≈ºeniu r√≥wnomierny?


```python
categorical_variables = variable_info[(variable_info['type']=='Categorical')]['name']
categorical_variables
```




    1         sex
    2          cp
    5         fbs
    6     restecg
    8       exang
    10      slope
    12       thal
    Name: name, dtype: object




```python
categorical_df = X[categorical_variables]
categorical_df
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sex</th>
      <th>cp</th>
      <th>fbs</th>
      <th>restecg</th>
      <th>exang</th>
      <th>slope</th>
      <th>thal</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
      <td>0</td>
      <td>3</td>
      <td>6.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>4</td>
      <td>0</td>
      <td>2</td>
      <td>1</td>
      <td>2</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>4</td>
      <td>0</td>
      <td>2</td>
      <td>1</td>
      <td>2</td>
      <td>7.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>3</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>3</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>1</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>298</th>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>7.0</td>
    </tr>
    <tr>
      <th>299</th>
      <td>1</td>
      <td>4</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>7.0</td>
    </tr>
    <tr>
      <th>300</th>
      <td>1</td>
      <td>4</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>2</td>
      <td>7.0</td>
    </tr>
    <tr>
      <th>301</th>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>2</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>302</th>
      <td>1</td>
      <td>3</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>3.0</td>
    </tr>
  </tbody>
</table>
<p>303 rows √ó 7 columns</p>
</div>




```python
for column in categorical_df.columns:
    plt.figure(figsize=(6, 6))
    categorical_df[column].value_counts().plot(kind='pie', autopct='%1.1f%%')
    plt.title(f'Pie Chart for {column}')
    plt.ylabel('')
    plt.show()
```


    
![png](../media/Lab01_files/Lab02_32_0.png)
    



    
![png](../media/Lab01_files/Lab02_32_1.png)
    



    
![png](../media/Lab01_files/Lab02_32_2.png)
    



    
![png](../media/Lab01_files/Lab02_32_3.png)
    



    
![png](../media/Lab01_files/Lab02_32_4.png)
    



    
![png](../media/Lab01_files/Lab02_32_5.png)
    



    
![png](../media/Lab01_files/Lab02_32_6.png)
    


Rozk≈Çad warto≈õci atrybut√≥w kategorycznych jest r√≥≈ºny, w wiƒôkszo≈õci przypadk√≥w nier√≥wnomierny, zale≈ºnie od atrybutu.
w niekt√≥rych przypadkach jest spora dysproporcja w danych, ale przewa≈ºnie dla jednego z 3 przypadk√≥w.
np. **thal,slope,restec**
W przypadku **sex, fbs** znacznie przewa≈ºa jedna kategoria.
Najbardziej r√≥wnomierny jest zbi√≥r **cp**


## 5. Czy wystƒôpujƒÖ cechy brakujƒÖce i jakƒÖ strategiƒô mo≈ºemy zastosowaƒá ≈ºeby je zastƒÖpiƒá?


```python
X.isnull().sum().sort_values(ascending=False)
```




    ca          4
    thal        2
    age         0
    sex         0
    cp          0
    trestbps    0
    chol        0
    fbs         0
    restecg     0
    thalach     0
    exang       0
    oldpeak     0
    slope       0
    dtype: int64




```python
y.isnull().sum()
```




    num    0
    dtype: int64



W przypadku **ca** uzupe≈Çniƒô brakujƒÖce warto≈õci ≈õredniƒÖ. Poniewa≈º jest to warto≈õƒá numeryczna. W przypadku **thal** uzupe≈Çniƒô je modƒÖ, poniewa≈º jest to atrybut kategoryczny.


```python
X
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>age</th>
      <th>sex</th>
      <th>cp</th>
      <th>trestbps</th>
      <th>chol</th>
      <th>fbs</th>
      <th>restecg</th>
      <th>thalach</th>
      <th>exang</th>
      <th>oldpeak</th>
      <th>slope</th>
      <th>ca</th>
      <th>thal</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>63</td>
      <td>1</td>
      <td>1</td>
      <td>145</td>
      <td>233</td>
      <td>1</td>
      <td>2</td>
      <td>150</td>
      <td>0</td>
      <td>2.3</td>
      <td>3</td>
      <td>0.0</td>
      <td>6.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>67</td>
      <td>1</td>
      <td>4</td>
      <td>160</td>
      <td>286</td>
      <td>0</td>
      <td>2</td>
      <td>108</td>
      <td>1</td>
      <td>1.5</td>
      <td>2</td>
      <td>3.0</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>67</td>
      <td>1</td>
      <td>4</td>
      <td>120</td>
      <td>229</td>
      <td>0</td>
      <td>2</td>
      <td>129</td>
      <td>1</td>
      <td>2.6</td>
      <td>2</td>
      <td>2.0</td>
      <td>7.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>37</td>
      <td>1</td>
      <td>3</td>
      <td>130</td>
      <td>250</td>
      <td>0</td>
      <td>0</td>
      <td>187</td>
      <td>0</td>
      <td>3.5</td>
      <td>3</td>
      <td>0.0</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>41</td>
      <td>0</td>
      <td>2</td>
      <td>130</td>
      <td>204</td>
      <td>0</td>
      <td>2</td>
      <td>172</td>
      <td>0</td>
      <td>1.4</td>
      <td>1</td>
      <td>0.0</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>298</th>
      <td>45</td>
      <td>1</td>
      <td>1</td>
      <td>110</td>
      <td>264</td>
      <td>0</td>
      <td>0</td>
      <td>132</td>
      <td>0</td>
      <td>1.2</td>
      <td>2</td>
      <td>0.0</td>
      <td>7.0</td>
    </tr>
    <tr>
      <th>299</th>
      <td>68</td>
      <td>1</td>
      <td>4</td>
      <td>144</td>
      <td>193</td>
      <td>1</td>
      <td>0</td>
      <td>141</td>
      <td>0</td>
      <td>3.4</td>
      <td>2</td>
      <td>2.0</td>
      <td>7.0</td>
    </tr>
    <tr>
      <th>300</th>
      <td>57</td>
      <td>1</td>
      <td>4</td>
      <td>130</td>
      <td>131</td>
      <td>0</td>
      <td>0</td>
      <td>115</td>
      <td>1</td>
      <td>1.2</td>
      <td>2</td>
      <td>1.0</td>
      <td>7.0</td>
    </tr>
    <tr>
      <th>301</th>
      <td>57</td>
      <td>0</td>
      <td>2</td>
      <td>130</td>
      <td>236</td>
      <td>0</td>
      <td>2</td>
      <td>174</td>
      <td>0</td>
      <td>0.0</td>
      <td>2</td>
      <td>1.0</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>302</th>
      <td>38</td>
      <td>1</td>
      <td>3</td>
      <td>138</td>
      <td>175</td>
      <td>0</td>
      <td>0</td>
      <td>173</td>
      <td>0</td>
      <td>0.0</td>
      <td>1</td>
      <td>NaN</td>
      <td>3.0</td>
    </tr>
  </tbody>
</table>
<p>303 rows √ó 13 columns</p>
</div>




```python
most_frequent_number_of_v = X['ca'].mode().iloc[0]
X.loc[:, 'ca'] = X['ca'].fillna(most_frequent_number_of_v)
most_frequent_category = X['thal'].mode().iloc[0]
X.loc[:, 'thal'] = X['thal'].fillna(most_frequent_category)
X.isnull().sum().sort_values(ascending=False)
```




    age         0
    sex         0
    cp          0
    trestbps    0
    chol        0
    fbs         0
    restecg     0
    thalach     0
    exang       0
    oldpeak     0
    slope       0
    ca          0
    thal        0
    dtype: int64



## 6. kod przekszta≈ÇcajƒÖcy dane do macierzy cech liczbowych (przyk≈Çady √ó cechy).


```python
df = pd.get_dummies(X, columns=['cp', 'restecg', 'slope', 'thal'],
                              prefix=['cp', 'restecg', 'slope', 'thal']).astype('int64')
df
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>age</th>
      <th>sex</th>
      <th>trestbps</th>
      <th>chol</th>
      <th>fbs</th>
      <th>thalach</th>
      <th>exang</th>
      <th>oldpeak</th>
      <th>ca</th>
      <th>cp_1</th>
      <th>...</th>
      <th>cp_4</th>
      <th>restecg_0</th>
      <th>restecg_1</th>
      <th>restecg_2</th>
      <th>slope_1</th>
      <th>slope_2</th>
      <th>slope_3</th>
      <th>thal_3.0</th>
      <th>thal_6.0</th>
      <th>thal_7.0</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>63</td>
      <td>1</td>
      <td>145</td>
      <td>233</td>
      <td>1</td>
      <td>150</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>67</td>
      <td>1</td>
      <td>160</td>
      <td>286</td>
      <td>0</td>
      <td>108</td>
      <td>1</td>
      <td>1</td>
      <td>3</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>67</td>
      <td>1</td>
      <td>120</td>
      <td>229</td>
      <td>0</td>
      <td>129</td>
      <td>1</td>
      <td>2</td>
      <td>2</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>37</td>
      <td>1</td>
      <td>130</td>
      <td>250</td>
      <td>0</td>
      <td>187</td>
      <td>0</td>
      <td>3</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>41</td>
      <td>0</td>
      <td>130</td>
      <td>204</td>
      <td>0</td>
      <td>172</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>298</th>
      <td>45</td>
      <td>1</td>
      <td>110</td>
      <td>264</td>
      <td>0</td>
      <td>132</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>299</th>
      <td>68</td>
      <td>1</td>
      <td>144</td>
      <td>193</td>
      <td>1</td>
      <td>141</td>
      <td>0</td>
      <td>3</td>
      <td>2</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>300</th>
      <td>57</td>
      <td>1</td>
      <td>130</td>
      <td>131</td>
      <td>0</td>
      <td>115</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>301</th>
      <td>57</td>
      <td>0</td>
      <td>130</td>
      <td>236</td>
      <td>0</td>
      <td>174</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>302</th>
      <td>38</td>
      <td>1</td>
      <td>138</td>
      <td>175</td>
      <td>0</td>
      <td>173</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>303 rows √ó 22 columns</p>
</div>



# Lab02 Prosta klasyfikacja



```python
X
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>age</th>
      <th>sex</th>
      <th>cp</th>
      <th>trestbps</th>
      <th>chol</th>
      <th>fbs</th>
      <th>restecg</th>
      <th>thalach</th>
      <th>exang</th>
      <th>oldpeak</th>
      <th>slope</th>
      <th>ca</th>
      <th>thal</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>63</td>
      <td>1</td>
      <td>1</td>
      <td>145</td>
      <td>233</td>
      <td>1</td>
      <td>2</td>
      <td>150</td>
      <td>0</td>
      <td>2.3</td>
      <td>3</td>
      <td>0.0</td>
      <td>6.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>67</td>
      <td>1</td>
      <td>4</td>
      <td>160</td>
      <td>286</td>
      <td>0</td>
      <td>2</td>
      <td>108</td>
      <td>1</td>
      <td>1.5</td>
      <td>2</td>
      <td>3.0</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>67</td>
      <td>1</td>
      <td>4</td>
      <td>120</td>
      <td>229</td>
      <td>0</td>
      <td>2</td>
      <td>129</td>
      <td>1</td>
      <td>2.6</td>
      <td>2</td>
      <td>2.0</td>
      <td>7.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>37</td>
      <td>1</td>
      <td>3</td>
      <td>130</td>
      <td>250</td>
      <td>0</td>
      <td>0</td>
      <td>187</td>
      <td>0</td>
      <td>3.5</td>
      <td>3</td>
      <td>0.0</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>41</td>
      <td>0</td>
      <td>2</td>
      <td>130</td>
      <td>204</td>
      <td>0</td>
      <td>2</td>
      <td>172</td>
      <td>0</td>
      <td>1.4</td>
      <td>1</td>
      <td>0.0</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>298</th>
      <td>45</td>
      <td>1</td>
      <td>1</td>
      <td>110</td>
      <td>264</td>
      <td>0</td>
      <td>0</td>
      <td>132</td>
      <td>0</td>
      <td>1.2</td>
      <td>2</td>
      <td>0.0</td>
      <td>7.0</td>
    </tr>
    <tr>
      <th>299</th>
      <td>68</td>
      <td>1</td>
      <td>4</td>
      <td>144</td>
      <td>193</td>
      <td>1</td>
      <td>0</td>
      <td>141</td>
      <td>0</td>
      <td>3.4</td>
      <td>2</td>
      <td>2.0</td>
      <td>7.0</td>
    </tr>
    <tr>
      <th>300</th>
      <td>57</td>
      <td>1</td>
      <td>4</td>
      <td>130</td>
      <td>131</td>
      <td>0</td>
      <td>0</td>
      <td>115</td>
      <td>1</td>
      <td>1.2</td>
      <td>2</td>
      <td>1.0</td>
      <td>7.0</td>
    </tr>
    <tr>
      <th>301</th>
      <td>57</td>
      <td>0</td>
      <td>2</td>
      <td>130</td>
      <td>236</td>
      <td>0</td>
      <td>2</td>
      <td>174</td>
      <td>0</td>
      <td>0.0</td>
      <td>2</td>
      <td>1.0</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>302</th>
      <td>38</td>
      <td>1</td>
      <td>3</td>
      <td>138</td>
      <td>175</td>
      <td>0</td>
      <td>0</td>
      <td>173</td>
      <td>0</td>
      <td>0.0</td>
      <td>1</td>
      <td>0.0</td>
      <td>3.0</td>
    </tr>
  </tbody>
</table>
<p>303 rows √ó 13 columns</p>
</div>




```python
y = y.map(lambda x: 1 if x in (1,2,3,4) else 0)
y
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>num</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
    </tr>
    <tr>
      <th>298</th>
      <td>1</td>
    </tr>
    <tr>
      <th>299</th>
      <td>1</td>
    </tr>
    <tr>
      <th>300</th>
      <td>1</td>
    </tr>
    <tr>
      <th>301</th>
      <td>1</td>
    </tr>
    <tr>
      <th>302</th>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>303 rows √ó 1 columns</p>
</div>



# Export przeanalizowanych i uzupelnionych plikow do csv


```python
from pathlib import Path
```


```python
csv_X_path = Path('../Dataset/X.csv')
csv_y_path = Path('../Dataset/y.csv')
```


```python
X.to_csv(csv_X_path,index=False)
y.to_csv(csv_y_path,index=False)
```

## Lab02
Sieci Neuronowe

Wynikiem implementacji listy jest program podzielony na 3 pliki:

- Functions.py -- funkcje pomocnicze, dyskretyzacja danych,
  normalizacja danych, obliczenie metryk dla zestawu testowego.

- Main.py -- ≈õrodowisko testowe, w nim testuje wizualizuje
  zaimplementowane metody i funkcje.

- NeuralNetwork.py -- klasa prostej sieci neuronowej, opartej na
  gradiencie z entropii krzy≈ºowej.

Implementacja rozwiƒÖzania:

Wyj≈õcie w sieci by≈Ço implementowane na wz√≥r:

ùëù(ùë•) = ùúé(ùëäùë• + ùëè)

``` Python
    def p(self, x):
        argument = np.dot(x, self.W) + self.b
        return self.sigmoid(argument)
```
gdzie funkcja sigmoid to:

<div style="text-align:center;">
 
  $\sigma(n) = \frac{1}{1 + e^{-n}}$
</div>

Co w pythonie mo≈ºe byƒá osiƒÖgniƒôte za pomocƒÖ funkcji
[expit(x)](https://docs.scipy.org/doc/scipy/reference/generated/scipy.special.expit.html)
:

``` Python
    def sigmoid(self, n):
    return expit(n)
```
Jako funkcjƒô kosztu wykorzystujemy entropiƒô krzy≈ºowƒÖ:
<div style="text-align:center;">
    ùêø = ‚àíùë¶ ln ùëù(ùë•) ‚àí (1 ‚àí ùë¶) ln(1 ‚àí ùëù(ùë•))
</div>

``` Python
    def cross_entropy_loss(self, y, y_pred):
        epsilon = 1e-15
        loss = y * np.log(y_pred + epsilon) + (1 - y) * np.log(1 - y_pred +epsilon)
        return -np.sum(loss)
```
epsilon zosta≈Ç dodany poniewa≈º by≈Ç problem z liczeniem warto≈õci 0.

Implementacja gradientu bƒôdzie za pomocƒÖ pochodnej po wagach modelu, co
z entropii krzy≈ºowej daje:
<div style="display: flex; justify-content: center; align-items: center; height: 200px;">
  
  $\frac{\partial L}{\partial w_i} = -(y - p(x))x$
  
  $\frac{\partial L}{\partial w_i} = (p(x) - y)x$
  
</div>

``` Python
    def compute_gradient(self, X_train, y_train):
        y_pred = self.p(X_train)
        dz = y_pred - y_train
        dw = np.dot(X_train.T, dz)
        db = np.sum(dz)
        return dw, db
```
Model uczy siƒô na podstawie zmiany wag, tak aby i≈õƒá w stronƒô wyznaczonƒÖ
przez gradient. Implementacja:

ùë§~i~‚Ä≤ = ùë§~ùëñ~ ‚àí ùõº $\frac{\partial L\ }{\partial wi}$

``` Python
    dw, db = self.compute_gradient(X_train, y_train)
```

Aktualizacja wag i bias zgodnie z gradientem i wsp√≥≈Çczynnikiem
uczenia:

``` Python
    self.W -= self.learning_rate * dw
    self.b -= self.learning_rate * db
```
M√≥j model posiada r√≥wnie≈º 3 funkcje kt√≥re mogƒÖ go wyuczyƒá:

- Fit_model_covergence -- kt√≥ry m√≥wi o wystarczajƒÖco ma≈Çej zmianie aby
  przerwaƒá proces uczenia.

- Fit -- podstawowa wersja uczƒÖca model, przechodzƒÖca przez ca≈Çy zbi√≥r
  X razy.

- Fit_batches -- wersja rozszerzona o dzielenie zbioru na paczki o
  nadanej wielko≈õci, przechodzi przez zbi√≥r X razy.

Aby zmaksymalizowaƒá uczenie siƒô modelu, dane przed ka≈ºdƒÖ iteracjƒÖ sƒÖ
losowo mieszane.

Aby zobaczyƒá wp≈Çyw procesowania danych bƒôdƒô rozpatrywa≈Ç wszystkie wyniki
kontek≈õcie 3 metod procesowania:

- Normalizacja

- Dyskretyzacja

- Surowe dane

Hiperparametry i parametry zosta≈Çy wybrane dla ka≈ºdego osobno tak aby
zmaksymalizowaƒá ich potencja≈Ç.

Wyniki uczenia dla parametrow i hiperparametr√≥w:

**Surowe dane**

``` Python
    learning_rate_basic_without_b = 0.1
    learning_rate_basic_with_b = 0.001
    num_of_iterations_basic = 400
    batch_size = 100
```
| Obraz 1                            | Obraz 2                            | Obraz 3                            | Obraz 4                            |
|------------------------------------|------------------------------------|------------------------------------|------------------------------------|
| ![Obraz 1](media/basic_data_1.png) | ![Obraz 2](media/basic_data_2.png) | ![Obraz 3](media/basic_data_3.png) | ![Obraz 4](media/basic_data_4.png) |
| Obraz 5                            | Obraz 6                            | Obraz 7                            | Obraz 8                            |
| ![Obraz 5](media/basic_data_5.png) | ![Obraz 6](media/basic_data_6.png) | ![Obraz 7](media/basic_data_7.png) | ![Obraz 8](media/basic_data_8.png) |

Mo≈ºemy stƒÖd zauwa≈ºyƒá, ≈ºe dane paczkowane, majƒÖ lepszy wynik ale sƒÖ mniej
stabilne je≈õli chodzi o metryki i proces uczenia.

Jendak oba wyniki sƒÖ bardzo dobre, plasujƒÖ siƒô na poziomie \>=0.6 je≈õli
chodzi o wszystkie metryki, co jest lepsze ni≈º losowe zgadywanie.
Najlepsza

**Dane poddane dyskretyzacji:**

``` Python
learning_rate_discrete_without_b = 0.0005
learning_rate_discrete_with_b = 0.0005
batch_size = 64
num_of_iterations_discretization = 60
```
| Obraz 1                                 | Obraz 2                                 | Obraz 3                                 | Obraz 4                                 |
|-----------------------------------------|-----------------------------------------|-----------------------------------------|-----------------------------------------|
| ![Obraz 1](media/discretize_data_1.png) | ![Obraz 2](media/discretize_data_2.png) | ![Obraz 3](media/discretize_data_3.png) | ![Obraz 4](media/discretize_data_4.png) |
| Obraz 5                                 | Obraz 6                                 | Obraz 7                                 | Obraz 8                                 |
| ![Obraz 5](media/discretize_data_5.png) | ![Obraz 6](media/discretize_data_6.png) | ![Obraz 7](media/discretize_data_7.png) | ![Obraz 8](media/discretize_data_8.png) |

**Dane poddane normalizacji:**

``` Python
learning_rate_normalization_without_b = 0.001
learning_rate_normalization_with_b = 0.001
num_of_iterations_normalization = 200
batch_size= 128
```
| Obraz 1                                | Obraz 2                                | Obraz 3                                | Obraz 4                                |
|----------------------------------------|----------------------------------------|----------------------------------------|----------------------------------------|
| ![Obraz 1](media/normalize_data_1.png) | ![Obraz 2](media/normalize_data_2.png) | ![Obraz 3](media/normalize_data_3.png) | ![Obraz 4](media/normalize_data_4.png) |
| Obraz 5                                | Obraz 6                                | Obraz 7                                | Obraz 8                                |
| ![Obraz 5](media/normalize_data_5.png) | ![Obraz 6](media/normalize_data_6.png) | ![Obraz 7](media/normalize_data_7.png) | ![Obraz 8](media/normalize_data_8.png) |

W tym przypadku mo≈ºemy zauwa≈ºyƒá, ≈ºe jest zdecydowanie mniej iteracji bo
tylko 60 i model siƒô stabilizuje, w przypadku paczkowania pomimo braku
wyra≈∫nej r√≥≈ºnicy na wykresie kosztu mo≈ºemy zauwa≈ºyƒá r√≥≈ºnicƒô w miarach.
Wszystkie testowe miary wskazujƒÖ ok. 90% poprawno≈õci, co jest wspania≈Çym
wynikiem.

W przypadku paczkowania mo≈ºemy tak≈ºe zauwa≈ºyƒá mniejsze wahania metryk.

Wnioski:

Dobranie odpowiednich parametr√≥w i hiperparametr√≥w odgrywa kluczowƒÖ rolƒô
w powodzeniu modelu. Jest to ciƒô≈ºkie bez znajomo≈õci metod na znalezienie
optmalnych wsp√≥≈Çczynnik√≥w, trzeba sprawdzaƒá to metodƒÖ pr√≥b i b≈Çƒôd√≥w.

Preprocessing te≈º odgrywa wa≈ºnƒÖ rolƒô w tym jak sprawuje siƒô model.

Nawet taki prosty model mo≈ºe sobie dobrze radziƒá z binarnƒÖ klasyfikacjƒÖ.

## Lab03
